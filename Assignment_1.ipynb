{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a895bf7",
   "metadata": {},
   "source": [
    "First you need to check wheather your environment has scipy installed or not.\n",
    "If not run \"pip install scipy\" in your terminal to install it and then run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fca1685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Links dataset:\n",
      "   movieId  imdbId   tmdbId\n",
      "0        1  114709    862.0\n",
      "1        2  113497   8844.0\n",
      "2        3  113228  15602.0\n",
      "3        4  114885  31357.0\n",
      "4        5  113041  11862.0\n",
      "\n",
      "movies dataset:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "\n",
      "Ratings dataset:\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "\n",
      "Tags dataset:\n",
      "   userId  movieId              tag   timestamp\n",
      "0       2    60756            funny  1445714994\n",
      "1       2    60756  Highly quotable  1445714996\n",
      "2       2    60756     will ferrell  1445714992\n",
      "3       2    89774     Boxing story  1445715207\n",
      "4       2    89774              MMA  1445715200\n",
      "\n",
      "\n",
      "Total number of ratings in the dataset is:100836\n"
     ]
    }
   ],
   "source": [
    "#A\n",
    "#Import the datasets and print some of the values to check the importing is ok\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#Load the 100k movie datasets\n",
    "\n",
    "links = pd.read_csv('links.csv', sep = ',')\n",
    "movies = pd.read_csv('movies.csv', sep = ',')\n",
    "ratings = pd.read_csv('ratings.csv', sep = ',')\n",
    "tags = pd.read_csv('tags.csv', sep = ',')\n",
    "\n",
    "#Display first few rows of each datasets to check the importing\n",
    "print(\"\\nLinks dataset:\")\n",
    "print(links.head())\n",
    "\n",
    "print(\"\\nmovies dataset:\")\n",
    "print(movies.head())\n",
    "\n",
    "print(\"\\nRatings dataset:\")\n",
    "print(ratings.head())\n",
    "\n",
    "print(\"\\nTags dataset:\")\n",
    "print(tags.head())\n",
    "\n",
    "num_of_ratings = len(ratings)\n",
    "print(f\"\\n\\nTotal number of ratings in the dataset is:{num_of_ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3c39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B\n",
    "#user based collaborative filtering approach using pearson correlation function to calculate similarities between users\n",
    "#User item matrix\n",
    "user_item_matrix = ratings.pivot(index = 'userId', columns = 'movieId', values = 'rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece5ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the Pearson Correlation between 44 and 188 = -0.0046249672160630605\n"
     ]
    }
   ],
   "source": [
    "#Pearson Correlation function between two users\n",
    "def pearson_correlation(user_1, user_2):\n",
    "    common_movies = user_item_matrix.loc[user_1].index.intersection(user_item_matrix.loc[user_2].index)\n",
    "    #Atleast 2 movies to compare\n",
    "    if len(common_movies) <2:\n",
    "        return 0\n",
    "    user_1_ratings = user_item_matrix.loc[user_1][common_movies]\n",
    "    user_2_ratings = user_item_matrix.loc[user_2][common_movies]\n",
    "    correlation, _ = pearsonr(user_1_ratings, user_2_ratings)\n",
    "    return correlation\n",
    "\n",
    "#Test\n",
    "user_1 = 44\n",
    "user_2 = 188\n",
    "print(f\"Check the Pearson Correlation between {user_1} and {user_2} = {pearson_correlation(user_1,user_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bc78cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting similar user\n",
    "def get_similar_user(target_user):\n",
    "    similarities = {}\n",
    "    for user in user_item_matrix.index:\n",
    "        if user != target_user:\n",
    "            similarity = pearson_correlation(target_user, user)\n",
    "            similarities[user] = similarity\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "612c0152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarities between 600 and all the other users are: {1: 0.26348073607017564, 2: 0.009476215521161388, 3: 0.00041563726687843597, 4: 0.1832692739564793, 5: 0.12458751478794813, 6: 0.1527884875902022, 7: 0.19819583083540315, 8: 0.15933034460084572, 9: 0.10773253816851812, 10: 0.0714213047724192, 11: 0.09784005317256406, 12: 0.06641221506383524, 13: 0.07292943502045261, 14: 0.1211159683701368, 15: 0.17641752288438095, 16: 0.19039747701381493, 17: 0.2314311779653644, 18: 0.20256011952933356, 19: 0.2875140111832335, 20: 0.22716875089206268, 21: 0.1129069152727071, 22: 0.1348454784901667, 23: 0.13296260121259268, 24: 0.12822719738026195, 25: 0.07078689467619342, 26: 0.11082731318544836, 27: 0.14230858730382406, 28: 0.1542286257549206, 29: 0.06874577341962924, 30: 0.10693563498528305, 31: 0.179863906325885, 32: 0.1451802659009671, 33: 0.14511570876924362, 34: 0.12219368085062068, 35: 0.0583467950102586, 36: 0.04551027045905543, 37: 0.11665720385608519, 38: 0.14422667877066964, 39: 0.2294908467376074, 40: 0.11688190333002244, 41: 0.18966785304439795, 42: 0.19952137541001977, 43: 0.1725178306085252, 44: 0.07120260989538019, 45: 0.3071923601705119, 46: 0.12934942620793866, 47: 0.10046142204638128, 48: 0.0823683541945154, 49: 0.05317883781662549, 50: 0.15722438200964922, 51: 0.19584512121100356, 52: 0.07603150215634824, 53: 0.002129345856127888, 54: 0.13551644440625715, 55: 0.012799390092575379, 56: 0.13594001858182617, 57: 0.25344635124891673, 58: 0.18955712216625786, 59: 0.11778585332182293, 60: 0.04107441804924, 61: 0.12166114210176737, 62: 0.1297866896821966, 63: 0.2418689058498599, 64: 0.35396298494403117, 65: 0.08654929630019945, 66: 0.24837150021926416, 67: 0.12004278610822473, 68: 0.30808206023751805, 69: 0.11097386846414745, 70: 0.10899443954758523, 71: 0.1162934614069385, 72: 0.16935728573096773, 73: 0.0713316196310048, 74: 0.11220998322843918, 75: 0.12130460806840924, 76: 0.16417976904953988, 77: 0.1486999287603677, 78: 0.15350847616035357, 79: 0.08577359770046927, 80: 0.07782128973663568, 81: 0.1283932519605991, 82: 0.16221021110229966, 83: 0.1557742568789824, 84: 0.19151928805759383, 85: 0.007940444335709061, 86: 0.189125601721506, 87: 0.142520030356236, 88: 0.1131750636353955, 89: 0.01176345296085831, 90: 0.06802539818974909, 91: 0.30703268848400056, 92: 0.055268416781417945, 93: 0.16085810838890308, 94: 0.1683919427837457, 95: 0.1686505858886856, 96: 0.14440708138352523, 97: 0.06811408861010272, 98: 0.08667669609236825, 99: 0.09333813282844369, 100: 0.1836693657630471, 101: 0.10246626455316143, 102: 0.1419767638669046, 103: 0.28775611074298113, 104: 0.1993444311436334, 105: 0.12354268708446695, 106: 0.09144457775582596, 107: 0.12193672564349631, 108: 0.0855403830108041, 109: 0.13804561637253912, 110: 0.09926453264968002, 111: 0.1191324518293144, 112: 0.18606899275098188, 113: 0.08928047453435695, 114: 0.10252350887823161, 115: 0.15394283934163944, 116: 0.17824661121595228, 117: 0.19701287240134344, 118: 0.07597454538537797, 119: 0.05791427048729217, 120: 0.1107937732758242, 121: 0.1331036614433054, 122: 0.2239409094649567, 123: 0.07771438737139055, 124: 0.17019056532983068, 125: 0.09194765753037969, 126: 0.1539292855326128, 127: 0.0446032347479542, 128: 0.09729359538752622, 129: 0.20317378200169856, 130: 0.12265995247445848, 131: 0.12761221763046837, 132: 0.3629049980725698, 133: 0.14167135135450634, 134: 0.1004939005474226, 135: 0.28633651596907667, 136: 0.1302666699780109, 137: 0.1869472277035119, 138: 0.0073959852520969005, 139: 0.09302073155216034, 140: 0.1481062008804351, 141: 0.21580338548049172, 142: 0.13568972668223842, 143: 0.05617074762011246, 144: 0.26082067954569516, 145: 0.09296341612381381, 146: 0.0688057044937476, 147: 0.05434645712961326, 148: 0.08177751294745411, 149: 0.12460839245304729, 150: 0.09338549586265796, 151: 0.08283706502233829, 152: 0.0943914565376153, 153: 0.1347680866374924, 154: 0.006713721703337333, 155: 0.07809824129665024, 156: 0.24090983364204938, 157: 0.07832706614308022, 158: 0.041686783018418404, 159: 0.11246886761023128, 160: 0.26350621250334016, 161: 0.08727373390735485, 162: 0.08999053354876232, 163: 0.05843871739766304, 164: 0.10758596511180392, 165: 0.10539175663851237, 166: 0.2655437967351818, 167: 0.23884655669057867, 168: 0.08785151833951335, 169: 0.2521369059220116, 170: 0.1379409656774794, 171: 0.16351710278034137, 172: 0.11022466910476691, 173: 0.11914511331970837, 174: 0.1532707222662572, 175: 0.004195459244846579, 176: 0.10767460027913664, 177: 0.2793041677077568, 178: 0.18741315735062591, 179: 0.16236062352584102, 180: 0.11851107511145452, 181: 0.1169003560874989, 182: 0.23925860950607744, 183: 0.06603625817379774, 184: -0.008202639140808566, 185: 0.13698897837347102, 186: 0.2185816849074988, 187: 0.2074697652263718, 188: 0.08791409328964311, 189: 0.1227409867058187, 190: 0.16247205266330306, 191: 0.058745177638310636, 192: 0.09710352402246844, 193: 0.16084243505988055, 194: 0.05472941918386818, 195: 0.1797964657603094, 196: 0.06817779467374703, 197: 0.07321308099286633, 198: 0.2636213089356393, 199: 0.18602212519358183, 200: 0.2978019552887214, 201: 0.24725069585980525, 202: 0.19010905617527177, 203: 0.10816225775803576, 204: 0.1271454376679505, 205: 0.0736925748759707, 206: 0.09108741141345177, 207: 0.06634195668460749, 208: 0.07062598709469857, 209: 0.09878919807091613, 210: 0.06461439082560815, 211: 0.10507766280916059, 212: 0.13607763300304937, 213: 0.11483488391992588, 214: 0.09624435278929407, 215: 0.1720123295376083, 216: 0.171194230566392, 217: 0.208064963667277, 218: 0.12342158137081163, 219: 0.2587106352727835, 220: 0.2691655425673839, 221: 0.21165486475735748, 222: 0.15427045455758026, 223: 0.22081691170678608, 224: 0.15625012233532434, 225: 0.15429651718591897, 226: 0.34511904505217234, 227: 0.1331447865665729, 228: 0.06536293337744008, 229: 0.14596021773593318, 230: 0.20810068018519481, 231: 0.14963694598301183, 232: 0.19070438576001603, 233: 0.18854831733114524, 234: 0.19654141107056552, 235: 0.14765240138743102, 236: 0.09707853877888206, 237: 0.07260222914529142, 238: 0.007072600033093027, 239: 0.258452872366161, 240: 0.16114183132942564, 241: 0.10577827953296307, 242: 0.14255126960658598, 243: 0.08623597439637243, 244: 0.10291545617058195, 245: 0.015478499505270324, 246: 0.16981125815833173, 247: 0.22621493838285306, 248: 0.07178800011741424, 249: 0.15115651563937138, 250: 0.061387344685807636, 251: 0.10509117851424424, 252: 0.03532671095553703, 253: 0.09910882099268338, 254: 0.20198537402496736, 255: 0.09079793375981926, 256: 0.07983054915317593, 257: 0.07679972636919236, 258: 0.10185300540463404, 259: 0.09943212707074037, 260: 0.21161036926894589, 261: 0.12002238706210037, 262: 0.06615887151621247, 263: 0.23941051712817576, 264: 0.13997157598969387, 265: 0.18403690192060657, 266: 0.21891148119295398, 267: 0.1529445160691566, 268: 0.1369661053632792, 269: 0.056025073480119175, 270: 0.10709055784197516, 271: 0.11641668634863785, 272: 0.04274615235562243, 273: 0.13319581669571687, 274: 0.30120885276067755, 275: 0.21226966811207054, 276: 0.13483959511632176, 277: 0.07605588346468936, 278: 0.05135847537882805, 279: 0.15886336105979282, 280: 0.14274872702400068, 281: 0.07869451981934647, 282: 0.23886575261016157, 283: 0.10558238424775312, 284: 0.1482090472201101, 285: 0.05790432334756286, 286: 0.22223221788508707, 287: 0.19947578301607935, 288: 0.3451277248966491, 289: 0.06490405957539522, 290: 0.13357552841610776, 291: 0.052049525658070944, 292: 0.17004907925063506, 293: 0.11309199032927655, 294: 0.1874691434679469, 295: 0.0980793794001541, 296: 0.08300657428530062, 297: 0.0779620935721635, 298: 0.22583246010741276, 299: 0.07223641762711107, 300: 0.09515664364816304, 301: 0.2130293633237202, 302: 0.1172785994433084, 303: 0.12984453815416086, 304: 0.22008086584041986, 305: 0.17542851212892308, 306: 0.009435445404144992, 307: 0.38351677504272563, 308: 0.16689505037977065, 309: 0.07692491875621067, 310: 0.044316373882663074, 311: 0.058556493318127116, 312: 0.21072932347591988, 313: 0.24047377725972335, 314: 0.1515645529371099, 315: 0.07109744510049408, 316: 0.19579548169552474, 317: 0.14153965335112279, 318: 0.14230485571227358, 319: 0.07582020677674595, 320: -0.01212754448754079, 321: 0.16939134058622093, 322: 0.23367133311107574, 323: 0.15114396953630688, 324: 0.07089015494270774, 325: 0.1607690412813338, 326: 0.09430118406459587, 327: 0.099490139621301, 328: 0.2982506407522682, 329: 0.06182272648558521, 330: 0.34489110735897255, 331: 0.1341474559044879, 332: 0.2199716040268404, 333: 0.016247243928909878, 334: 0.2329180198241062, 335: 0.12410082208794318, 336: 0.1616403441203007, 337: 0.11057556905758614, 338: 0.08811401657848375, 339: 0.16822106002209086, 340: 0.12899707069939298, 341: 0.06698376168862205, 342: 0.083387659627363, 343: 0.13613628830278907, 344: 0.1362602624921812, 345: 0.06430906729207886, 346: 0.1888127439361741, 347: 0.16260173271999548, 348: 0.1595171147964473, 349: 0.13473109752161921, 350: 0.10824563503275988, 351: 0.0926883164576286, 352: 0.1264416295917573, 353: 0.12627683241849827, 354: 0.25862220857642926, 355: 0.05146436760351334, 356: 0.26694233156378194, 357: 0.32508865853890445, 358: 0.057284230633175934, 359: 0.16316441967833833, 360: 0.03876931953948653, 361: 0.11326993520964904, 362: 0.14711403328129508, 363: 0.1022718746535845, 364: 0.0945777121701813, 365: 0.11920799872875573, 366: 0.09181189666625089, 367: 0.18390430070886388, 368: 0.1454227554539323, 369: 0.176927980282906, 370: 0.24855493631792128, 371: 0.11987338781652741, 372: 0.184746332841579, 373: 0.1567786484059144, 374: 0.14052991717921207, 375: 0.11354314070255492, 376: 0.20453740651449737, 377: 0.08267547285646515, 378: 0.10283518675610744, 379: 0.14134357243933438, 380: 0.21832586302160656, 381: 0.32417152815812045, 382: 0.11705804542040488, 383: 0.07112126278778601, 384: 0.12662883707948772, 385: 0.21030575581898162, 386: 0.09301945050192074, 387: 0.3145666628984149, 388: 0.03935275730179414, 389: 0.08676402927138008, 390: 0.12262765543983092, 391: 0.25379515593460067, 392: 0.08049169439442319, 393: 0.13747832825451722, 394: 0.09838465093421589, 395: 0.14284435041920449, 396: 0.062014890022044536, 397: 0.06984758495265903, 398: 0.1458836759898805, 399: 0.18352716864364074, 400: 0.15075742442141754, 401: 0.08937451365267382, 402: 0.11438769423174705, 403: 0.0695102948987022, 404: 0.14541961788067403, 405: 0.09071351397958717, 406: 0.05404985935994941, 407: 0.10703589792205495, 408: 0.08828103264934226, 409: 0.1714502202391517, 410: 0.1308412370724205, 411: 0.1585500472716153, 412: 0.12800734822623575, 413: 0.09612263139125468, 414: 0.2928078203721295, 415: 0.1560921692055172, 416: 0.18216384073952135, 417: 0.16513240739102017, 418: 0.17492259628485263, 419: 0.12779973494779842, 420: 0.21538989629572847, 421: 0.08803995529416314, 422: 0.06383406139240666, 423: 0.0968687508993601, 424: 0.16814990121727738, 425: 0.25548073217288997, 426: 0.15750426844130927, 427: 0.07841817592427841, 428: 0.2534092149946299, 429: 0.07641352840436888, 430: 0.14244750462732053, 431: 0.03468864227816534, 432: 0.17852381378757903, 433: 0.09324286771220823, 434: 0.3086297375268393, 435: 0.06987913792354727, 436: 0.13358454633802247, 437: 0.13332714719656433, 438: 0.21735547411455255, 439: 0.12620431414930877, 440: 0.09805507516648991, 441: 0.1401285818502503, 442: 0.06817115288774063, 443: 0.12950791134616746, 444: 0.11330214965897334, 445: 0.21004604200738394, 446: 0.1750589737077466, 447: 0.14969168845699143, 448: 0.22047245388283637, 449: 0.14549671407988712, 450: 0.09481073394934297, 451: 0.09514650616349471, 452: 0.20054694368791123, 453: 0.23925521051513393, 454: 0.08586869117327364, 455: 0.15513645458980246, 456: 0.0868800948463323, 457: 0.13998626512836138, 458: 0.1484114674398685, 459: 0.07242083069871806, 460: 0.10548992121768933, 461: 0.1091664723888969, 462: 0.17115135840578338, 463: 0.08371560418807088, 464: 0.16299817490401297, 465: 0.09260948549080544, 466: 0.10637106503919261, 467: 0.03343020048715732, 468: 0.1365390313034475, 469: 0.2630692572129721, 470: 0.18742854185098623, 471: 0.09656681210710763, 472: 0.07976185690272039, 473: 0.13279232578519434, 474: 0.2933353037493704, 475: 0.1595818635447706, 476: 0.15086852075680973, 477: 0.3070695549490693, 478: 0.08963127457352452, 479: 0.1394247066447234, 480: 0.3938079245683672, 481: 0.03857102244609479, 482: 0.13406214175413586, 483: 0.3113931151681185, 484: 0.22465793051774657, 485: 0.10129950945953284, 486: 0.1269820139078204, 487: 0.1522932480463104, 488: 0.18967946175066358, 489: 0.3492463953130869, 490: 0.13517947082139337, 491: 0.07387077819543961, 492: 0.07889073902132113, 493: 0.09261252148813717, 494: 0.11018640090540907, 495: 0.13334423810966017, 496: 0.05823492172637172, 497: 0.16491630678724373, 498: 0.138531660205503, 499: 0.049719532165142216, 500: 0.13784907005715666, 501: 0.05795113817020559, 502: 0.12113944338392263, 503: 0.1299010106374977, 504: 0.12470479299785404, 505: 0.07868243238880071, 506: 0.012328571383315803, 507: 0.12088319471499104, 508: 0.06979830272120759, 509: 0.19534746388274232, 510: 0.17483332742734464, 511: 0.06589811777560164, 512: 0.17026248993613072, 513: 0.15971384764802604, 514: 0.2422355938354726, 515: 0.05272566341651773, 516: 0.10973358052573852, 517: 0.22922949959278643, 518: 0.03386168137701417, 519: 0.03751539819556608, 520: 0.21590045048105427, 521: 0.07681073316274423, 522: 0.16454595269784034, 523: 0.128680159543064, 524: 0.1618061940485782, 525: 0.2903705520134471, 526: 0.09369689146432764, 527: 0.1846652036010316, 528: 0.10158242518598384, 529: 0.09215582236699774, 530: 0.10709439309761845, 531: 0.11206755308655379, 532: 0.10847168821442445, 533: 0.08501117597764188, 534: 0.15517538243777368, 535: 0.07391574129533486, 536: 0.09681199012700331, 537: 0.07127989188030276, 538: 0.07996326568172003, 539: 0.07596005083816774, 540: 0.1485468808458587, 541: 0.12286103605791729, 542: 0.2178684022247528, 543: 0.11176555567758348, 544: 0.047437687632778544, 545: 0.009079272094731479, 546: 0.05587611514621856, 547: 0.04073777830102633, 548: 0.05862257946370965, 549: 0.1120386097328073, 550: 0.02253178497773419, 551: 0.11166108168366817, 552: 0.20153630611518936, 553: 0.08930214608412404, 554: 0.16557234901208767, 555: 0.2548575315857727, 556: 0.07780553171244364, 557: 0.14876637085567765, 558: 0.09324757783692572, 559: 0.16033519056658965, 560: 0.22115275705356335, 561: 0.2857887879717624, 562: 0.20816688781654108, 563: 0.08068129313138003, 564: 0.03374437188078962, 565: 0.11571785528669645, 566: 0.16590002422684128, 567: 0.05726117568367992, 568: 0.0667708913210007, 569: 0.09646611572560171, 570: 0.2942529459983958, 571: 0.10063452535662898, 572: 0.15425502744181036, 573: 0.21996444218254246, 574: 0.12459625597671396, 575: 0.05142964329063322, 576: 0.04975785662486224, 577: 0.164361260661315, 578: 0.014880635551429478, 579: 0.12139467017288932, 580: 0.2530850349773618, 581: 0.16752178457589015, 582: 0.05141213877011846, 583: 0.10849944738074792, 584: 0.15379150388748591, 585: 0.066984437708274, 586: 0.08881318975973197, 587: 0.15349746575577033, 588: 0.11126230869686923, 589: 0.10431620429291216, 590: 0.31213728394630036, 591: 0.10555164624738278, 592: 0.15176799536641505, 593: 0.22766701796973032, 594: 0.14139938005256358, 595: 0.037871755040371304, 596: 0.175767677011685, 597: 0.26387525671566325, 598: 0.048324832104693696, 599: 0.2790713939995457, 601: 0.13146066522564734, 602: 0.15521412112936211, 603: 0.17304941762655018, 604: 0.11736267244625229, 605: 0.21605957550824292, 606: 0.24461987399607443, 607: 0.19250130548856265, 608: 0.3237622053240269, 609: 0.09201181603650513, 610: 0.14089570075905963}\n"
     ]
    }
   ],
   "source": [
    "#test the similarity function\n",
    "target_user = 600\n",
    "print(f\"The similarities between {target_user} and all the other users are: {get_similar_user(target_user)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9531d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C\n",
    "#Predicting movie score of a user using the prediction function taught in the class\n",
    "def predict_movie_rating(target_user, movie):\n",
    "    target_user_movies = user_item_matrix.loc[target_user].index\n",
    "    common_users = user_item_matrix.loc[:, movie].dropna().index\n",
    "    movie_similarities = {user: pearson_correlation(target_user, user) for user in common_users}\n",
    "    weighted_sum = 0\n",
    "    sum_of_similarities = 0\n",
    "    \n",
    "    for user, similarity in movie_similarities.items():\n",
    "        rb = user_item_matrix.loc[user, movie]\n",
    "        rb_bar = user_item_matrix.loc[user].mean()\n",
    "        weighted_sum += similarity * (rb-rb_bar)\n",
    "        sum_of_similarities += abs(similarity)\n",
    "    \n",
    "    ra_bar = user_item_matrix.loc[target_user].mean()\n",
    "    if sum_of_similarities != 0:\n",
    "        predicted_movie_rating = ra_bar + (weighted_sum / sum_of_similarities)\n",
    "    else:\n",
    "        predicted_movie_rating = ra_bar\n",
    "        \n",
    "    return predicted_movie_rating\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85093ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 4 on movie 88: 0.09655699132940904\n"
     ]
    }
   ],
   "source": [
    "#Test predicted movie ratings\n",
    "target_user = 4\n",
    "movie = 88\n",
    "print(f\"Predicted rating for user {target_user} on movie {movie}: {predict_movie_rating(target_user, movie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3002e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D\n",
    "#Top 10 similar user of a particular user\n",
    "def get_top_similar_users(target_users, top_users=10):\n",
    "    similarities = get_similar_user(target_user)\n",
    "    top_users = sorted(similarities.items(), key=lambda x: x[1], reverse = True)[:top_users]\n",
    "    return top_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dffd72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 users for the user 88 are :\n",
      "[(247, 0.32680750780806667), (378, 0.31366013952545246), (189, 0.30893643035962837), (233, 0.2987884389402532), (434, 0.2983242583031804), (581, 0.2888730811017719), (460, 0.28565134916000706), (417, 0.2809637189442898), (254, 0.2740586943913226), (61, 0.2736996884275945)]\n"
     ]
    }
   ],
   "source": [
    "#Test similar users function\n",
    "target_user = 88\n",
    "\n",
    "print(f\"Top 10 users for the user {target_user} are :\\n{get_top_similar_users(target_user, 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30812adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 recommended movies for the user\n",
    "def user_based_movie_recommendations(target_user, top_movies = 10):\n",
    "    top_users = get_top_similar_users(target_user)\n",
    "    target_user_movies = user_item_matrix.loc[target_user].index\n",
    "    recommended_movies = []\n",
    "    for user, similarity in top_users:\n",
    "        similar_user_movies = user_item_matrix,loc[user].index\n",
    "        new_movies = [similar_user_movies] - [target_user_movies]\n",
    "        recommended_movies.update(new_movies)\n",
    "        if len(recommended_movies) >= top_movies:\n",
    "            break\n",
    "    \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d060224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#E\n",
    "#Implemanting new recommender system (for thus case it is a predifned cosine similarity function)\n",
    "import numpy as np\n",
    "def cosine_similarity(user_1, user_2):\n",
    "    common_movies = user_item_matrix.loc[user_1].index.intersection(user_item_matrix.loc[user_2].index)\n",
    "    if len(common_movies) == 0:\n",
    "        return 0\n",
    "    user_1_ratings = user_item_matrix.loc[user_1][common_movies]\n",
    "    user_2_ratings = user_item_matrix.loc[user_2][common_movies]\n",
    "    similarity = np.dot(user_1_ratings, user_2_ratings) / (np.linalg.norm(user_1_ratings) * np.linalg.norm(user_2_ratings))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc53b62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between user 55 and user 59: 0.01946719349585089\n"
     ]
    }
   ],
   "source": [
    "#Test the cosine similarity\n",
    "user_1 = 55\n",
    "user_2 = 59\n",
    "print(f\"Cosine similarity between user {user_1} and user {user_2}: {cosine_similarity(user_1, user_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a7ae5",
   "metadata": {},
   "source": [
    "Cosine similarity is better because it uses preference in multi-dimentional space of the users to measure the similarity between them. Some of the others reasons are as follows: Cosine similarity tends to be affected lessly by extreme ratings, so quite efficient with a larger dataset. It also can be used where users actually rated only a small amount of movies. Besides this, using different kinds of similarity metrics have different impact on the quality of the recommendations of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5201cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
